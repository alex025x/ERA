{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Data Cleaning Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "- Identify and handle any missing or erroneous data.\n",
        "- Use appropriate imputation methods for missing values.\n",
        "- Split the data into training and test sets.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "- `inputs/datasets/raw/WA_Fn-UseC_-HR-Employee-Attrition.csv`\n",
        "\n",
        "## Outputs\n",
        "\n",
        "- Cleaned train and test datasets.\n",
        "  - Path to the cleaned train set: `outputs/datasets/cleaned/TrainSetCleaned.csv`\n",
        "  - Path to the cleaned test set: `outputs/datasets/cleaned/TestSetCleaned.csv`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kspgyffxear-"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tdAGw4Zwssu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Collected data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2ELZj83tF1g",
        "outputId": "d51e2567-7f6c-4200-b9c2-d4982d22e6fd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"inputs/datasets/raw/WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iue5e5GJ_vZg"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From our exploratory data analysis, we identified certain columns with zero values that may not be accurate representations of the data. Specifically, MonthlyIncome and TotalWorkingYears contain zeros, which likely indicate missing or unrecorded information rather than valid data.\n",
        "\n",
        "- MonthlyIncome: 19 zeros (1.3% of data)\n",
        "\n",
        "- TotalWorkingYears: 11 zeros (0.7% of data)\n",
        "\n",
        "\n",
        "Instead of removing these rows, we will treat the zero values as missing data (NaN) and impute them to preserve as much information as possible. We will replace zeros in these columns with the median value, which is less sensitive to outliers and better maintains the data's integrity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyi3gi2-_q1j"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "columns_to_check = [\"MonthlyIncome\", \"TotalWorkingYears\"]\n",
        "for col in columns_to_check:\n",
        "    df[col] = df[col].replace(0, np.nan)\n",
        "\n",
        "# Function to evaluate missing data\n",
        "def EvaluateMissingData(df):\n",
        "    missing_data_absolute = df.isna().sum()\n",
        "    missing_data_percentage = round(missing_data_absolute/len(df)*100, 2)\n",
        "    df_missing_data = (pd.DataFrame(\n",
        "                            data={\"RowsWithMissingData\": missing_data_absolute,\n",
        "                                   \"PercentageOfDataset\": missing_data_percentage,\n",
        "                                   \"DataType\": df.dtypes}\n",
        "                                    )\n",
        "                          .sort_values(by=['PercentageOfDataset'], ascending=False)\n",
        "                          .query(\"PercentageOfDataset > 0\")\n",
        "                          )\n",
        "\n",
        "    return df_missing_data\n",
        "    \n",
        "EvaluateMissingData(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imputing Missing Values\n",
        "\n",
        "Now, the NaN values can be replaced with imputed values.\n",
        "\n",
        "- For numerical features like MonthlyIncome, we will use median imputation.\n",
        "\n",
        "- For categorical variables like JobRole, we will use mode imputation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from feature_engine.imputation import MeanMedianImputer, CategoricalImputer\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"median_imputation\", MeanMedianImputer(imputation_method=\"median\",\n",
        "                                            variables=[\"MonthlyIncome\", \"TotalWorkingYears\"])),\n",
        "    (\"frequent_imputation\", CategoricalImputer(imputation_method=\"frequent\",\n",
        "                                               variables=[\"JobRole\", \"MaritalStatus\"]))\n",
        "])\n",
        "\n",
        "# Apply the pipeline to the data\n",
        "cleaned_df = pipeline.fit_transform(df)\n",
        "\n",
        "# Evaluate missing data after imputation\n",
        "EvaluateMissingData(cleaned_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assess the Effect of Data Cleaning\n",
        "\n",
        "- Next we will visualize the distribution of cleaned features to ensure the cleaning process did not introduce bias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "def DataCleaningEffect(df_original, df_cleaned, variables_applied_with_method):\n",
        "    flag_count = 1\n",
        "    categorical_variables = df_original.select_dtypes(exclude=['number']).columns\n",
        "\n",
        "    for set_of_variables in [variables_applied_with_method]:\n",
        "        print(\"\\n=====================================================================================\")\n",
        "        print(f\"* Distribution Effect Analysis After Data Cleaning Method in the following variables:\")\n",
        "        print(f\"{set_of_variables} \\n\\n\")\n",
        "\n",
        "        for var in set_of_variables:\n",
        "            if var in categorical_variables:\n",
        "                df1 = pd.DataFrame({\"Type\": \"Original\", \"Value\": df_original[var]})\n",
        "                df2 = pd.DataFrame({\"Type\": \"Cleaned\", \"Value\": df_cleaned[var]})\n",
        "                dfAux = pd.concat([df1, df2], axis=0)\n",
        "                fig, axes = plt.subplots(figsize=(15, 5))\n",
        "                sns.countplot(hue='Type', data=dfAux, x=\"Value\", palette=[\"#432371\", \"#FAAE7B\"])\n",
        "                axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
        "                plt.xticks(rotation=90)\n",
        "                plt.legend()\n",
        "\n",
        "            else:\n",
        "                fig, axes = plt.subplots(figsize=(10, 5))\n",
        "                sns.histplot(data=df_original, x=var, color=\"#432371\", label=\"Original\", kde=True, element=\"step\", ax=axes)\n",
        "                sns.histplot(data=df_cleaned, x=var, color=\"#FAAE7B\", label=\"Cleaned\", kde=True, element=\"step\", ax=axes)\n",
        "                axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
        "                plt.legend()\n",
        "\n",
        "            plt.show()\n",
        "            flag_count += 1\n",
        "\n",
        "cleaned_features = [\"MonthlyIncome\", \"TotalWorkingYears\", \"JobRole\", \"MaritalStatus\"]\n",
        "DataCleaningEffect(df, cleaned_df, cleaned_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Split into Training and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define target and features\n",
        "X = cleaned_df.drop(\"Attrition\", axis=1)\n",
        "y = cleaned_df[\"Attrition\"]\n",
        "\n",
        "# Split the data into training and test sets\n",
        "TrainSet, TestSet, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "print(f\"TrainSet shape: {TrainSet.shape} \\nTestSet shape: {TestSet.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.makedirs('outputs/datasets/cleaned', exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TrainSet.to_csv(\"outputs/datasets/cleaned/TrainSetCleaned.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TestSet.to_csv(\"outputs/datasets/cleaned/TestSetCleaned.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
