{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Classification Model and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "Answer Business Requirement 2:\n",
        "\n",
        "- The client is interested in using employee data to predict whether an employee is at risk of leaving the company.\n",
        "\n",
        "- Fit and evaluate a classification model to predict if an employee will leave (attrition) or stay with the company.\n",
        "\n",
        "\n",
        "### Inputs\n",
        "\n",
        "- outputs/datasets/cleaned/TrainSetCleaned.csv\n",
        "- outputs/datasets/cleaned/TestSetCleaned.csv\n",
        "- Instructions on data cleaning and feature engineering from the relevant notebooks\n",
        "\n",
        "### Outputs\n",
        "\n",
        "- Data cleaning, feature engineering, and modeling pipelines\n",
        "- Feature importance plot\n",
        "- Model evaluation metrics for employee attrition prediction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to ensure that the working directory is correctly set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "current_dir = os.getcwd()\n",
        "current_dir\n",
        "\n",
        "# Set the working directory to the parent directory\n",
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")\n",
        "\n",
        "# Confirm the new current directory\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSpFreVRiuM3"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Load the cleaned training and test datasets that have been prepared with imputed values for MonthlyIncome, TotalWorkingYears, and any other necessary features, ready for the ML pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xk7DU_ekbtX8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the train set\n",
        "train_set_df = pd.read_csv(\"outputs/datasets/cleaned/TrainSetCleaned.csv\")\n",
        "train_set_df.head(3)\n",
        "\n",
        "# Load the test set\n",
        "test_set_df = pd.read_csv(\"outputs/datasets/cleaned/TestSetCleaned.csv\")\n",
        "test_set_df.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ofil7xTpm6l9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification ML Pipeline\n",
        "\n",
        "Pipeline for Data Cleaning and Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from feature_engine.imputation import MeanMedianImputer, CategoricalImputer\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "\n",
        "def DataCleaningandFeatEngPipeline():\n",
        "    pipeline = Pipeline([\n",
        "        (\"median_imputation\", MeanMedianImputer(imputation_method=\"median\", \n",
        "                                                variables=[\"MonthlyIncome\", \"TotalWorkingYears\"])),\n",
        "        (\"frequent_imputation\", CategoricalImputer(imputation_method=\"frequent\", \n",
        "                                                   variables=[\"JobRole\", \"MaritalStatus\"])),\n",
        "        (\"ordinal_encoding\", OrdinalEncoder(encoding_method=\"arbitrary\", \n",
        "                                            variables=[\"BusinessTravel\", \"Department\", \"EducationField\"]))\n",
        "    ])\n",
        "    return pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline for Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "def ClassificationPipeline(model):\n",
        "    pipeline = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"model\", model)\n",
        "    ])\n",
        "    return pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split Data into Train and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    train_set_df.drop(\"Attrition\", axis=1),\n",
        "    train_set_df[\"Attrition\"],\n",
        "    test_size=0.2,\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Target Distribution and Oversampling\n",
        "\n",
        "Check target distribution in the training set to evaluate balance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Check target distribution of the train set\n",
        "sns.set_style(\"whitegrid\")\n",
        "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "- The target looks relatively balanced, but in order to try and minimise overfitting,  oversampling will be done.\n",
        "\n",
        "- In order to do this, we first need to clean and encode the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Construct the data cleaning and feature engineering pipeline\n",
        "data_cleaning_feat_eng_pipeline = DataCleaningandFeatEngPipeline()\n",
        "\n",
        "# Apply the pipeline to clean and encode the training and test sets\n",
        "X_train = data_cleaning_feat_eng_pipeline.fit_transform(X_train, y_train)\n",
        "X_test = data_cleaning_feat_eng_pipeline.transform(X_test)\n",
        "\n",
        "# Display the shapes of the transformed datasets\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " We ensure all features are numeric, as SMOTE requires numeric input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "if len(non_numeric_columns) > 0:\n",
        "    encoder = OrdinalEncoder()\n",
        "    X_train[non_numeric_columns] = encoder.fit_transform(X_train[non_numeric_columns])\n",
        "    X_test[non_numeric_columns] = encoder.transform(X_test[non_numeric_columns])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the target is imbalanced, we will consider using SMOTE to balance the classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Apply SMOTE to the training set\n",
        "oversample = SMOTE(sampling_strategy='minority', random_state=0)\n",
        "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
        "\n",
        "# Display the shapes of the oversampled datasets\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we will verify the target distribution in the training set after applying SMOTE to confirm that the class imbalance has been addressed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Convert y_train back to a pandas Series to use value_counts()\n",
        "y_train_series = pd.Series(y_train)\n",
        "\n",
        "# Check target distribution after oversampling\n",
        "y_train_series.value_counts().plot(kind='bar', title='Train Set Target Distribution After SMOTE')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameter Optimization\n",
        "\n",
        "Load custom hyperparameter optimisation class from CodeInstitute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, recall_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class HyperparameterOptimizationSearch:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
        "\n",
        "            model = ClassificationPipeline(self.models[key])\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
        "                              verbose=verbose, scoring=scoring, refit=refit)\n",
        "            gs.fit(X, y)\n",
        "            self.grid_searches[key] = gs\n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                'estimator': key,\n",
        "                'min_score': min(scores),\n",
        "                'max_score': max(scores),\n",
        "                'mean_score': np.mean(scores),\n",
        "                'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params, **d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]\n",
        "                scores.append(r.reshape(len(params), 1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params, all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "        columns = ['estimator', 'min_score',\n",
        "                   'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "        return df[columns], self.grid_searches\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Definde Models and Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_quick_search = {\n",
        "    \"LogisticRegression\": LogisticRegression(random_state=0),\n",
        "    \"XGBClassifier\": XGBClassifier(random_state=0),\n",
        "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=0),\n",
        "    \"RandomForestClassifier\": RandomForestClassifier(random_state=0),\n",
        "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=0),\n",
        "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=0),\n",
        "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=0),\n",
        "}\n",
        "\n",
        "params_quick_search = {\n",
        "    \"LogisticRegression\": {},\n",
        "    \"XGBClassifier\": {},\n",
        "    \"DecisionTreeClassifier\": {},\n",
        "    \"RandomForestClassifier\": {},\n",
        "    \"GradientBoostingClassifier\": {},\n",
        "    \"ExtraTreesClassifier\": {},\n",
        "    \"AdaBoostClassifier\": {},\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the HyperparameterOptimizationSearch class to search for the best model using default parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "models_quick_search = {\n",
        "    \"LogisticRegression\": LogisticRegression(random_state=0),\n",
        "    \"XGBClassifier\": XGBClassifier(random_state=0),\n",
        "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=0),\n",
        "    \"RandomForestClassifier\": RandomForestClassifier(random_state=0),\n",
        "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=0),\n",
        "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=0),\n",
        "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=0),\n",
        "}\n",
        "\n",
        "params_quick_search = {\n",
        "    \"LogisticRegression\": {},\n",
        "    \"XGBClassifier\": {},\n",
        "    \"DecisionTreeClassifier\": {},\n",
        "    \"RandomForestClassifier\": {},\n",
        "    \"GradientBoostingClassifier\": {},\n",
        "    \"ExtraTreesClassifier\": {},\n",
        "    \"AdaBoostClassifier\": {},\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are using default hyperparameters to find best algorithm, scored by recall and as such fulfilling business requirement 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "non_numeric_columns = X_train.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "if len(non_numeric_columns) > 0:\n",
        "    encoder = OrdinalEncoder()\n",
        "    X_train[non_numeric_columns] = encoder.fit_transform(X_train[non_numeric_columns])\n",
        "    X_test[non_numeric_columns] = encoder.transform(X_test[non_numeric_columns])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Convert target labels to numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_test = label_encoder.transform(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import make_scorer, recall_score\n",
        "\n",
        "# Run the hyperparameter optimization\n",
        "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "search.fit(X_train, y_train,\n",
        "           scoring=make_scorer(recall_score, pos_label=1),  # Use numerical labels\n",
        "           n_jobs=-1, cv=5)\n",
        "\n",
        "# Summarize the results\n",
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Refining the Search with Specific Hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the results, we will select the top-performing models and refine the hyperparameter search:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import make_scorer, recall_score\n",
        "\n",
        "# Define the models to search\n",
        "models_search = {\n",
        "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=0),\n",
        "    \"LogisticRegression\": LogisticRegression(random_state=0),\n",
        "}\n",
        "\n",
        "params_search = {\n",
        "    \"AdaBoostClassifier\": {\n",
        "        \"model__n_estimators\": [50, 100, 200, 300],\n",
        "        \"model__learning_rate\": [0.001, 0.01, 0.1, 1.0],\n",
        "        \"model__algorithm\": [\"SAMME\", \"SAMME.R\"],\n",
        "    },\n",
        "    \"LogisticRegression\": {\n",
        "        \"model__penalty\": [\"l2\", \"l1\", \"elasticnet\", None],\n",
        "        \"model__C\": [10, 2, 1.0, 0.5, 0.1],\n",
        "        \"model__tol\": [1e-3, 1e-4, 1e-5],\n",
        "    },\n",
        "}\n",
        "\n",
        "# Run the hyperparameter optimization\n",
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train,\n",
        "           scoring=make_scorer(recall_score, pos_label=1),  # Use numerical labels\n",
        "           n_jobs=-1, cv=5)\n",
        "\n",
        "extensive_grid_search_summary, extensive_grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "print(extensive_grid_search_summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using extensive Hyperparameter options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train,\n",
        "           scoring=make_scorer(recall_score, pos_label=1),\n",
        "           n_jobs=-1, cv=5)\n",
        "\n",
        "extensive_grid_search_summary, extensive_grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "print(extensive_grid_search_summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on these results we will use AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Select and Save the Best Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Identify and save the best model and its parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = extensive_grid_search_summary.iloc[0, 0]\n",
        "best_parameters = extensive_grid_search_pipelines[best_model].best_params_\n",
        "\n",
        "print(\"Best Model:\", best_model)\n",
        "print(\"Best Parameters:\", best_parameters)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We identified the best model as AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# Rebuild the AdaBoostClassifier with the best parameters\n",
        "classification_pipeline = AdaBoostClassifier(\n",
        "    algorithm='SAMME.R',\n",
        "    learning_rate=1.0,\n",
        "    n_estimators=300,\n",
        "    random_state=0  # Keep random_state for reproducibility\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We fit the model using the training data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classification_pipeline.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once the model is fitted, we can save it for later use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the fitted model to a file\n",
        "joblib.dump(classification_pipeline, \"best_classification_pipeline.pkl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We evaluate the model right away:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "y_pred = classification_pipeline.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=['Stay', 'Leave']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "- Extracted feature importance from the final model (e.g., AdaBoostClassifier).\n",
        "\n",
        "- Key features: **Employee Number**, **Monthly Income**, and **Age**.\n",
        "\n",
        "- Lesser impact: **Education**, **Employee Count**.\n",
        "\n",
        "- Visual representation helps in understanding the model's focus.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check if the model has the `feature_importances_` attribute\n",
        "if hasattr(classification_pipeline, 'feature_importances_'):\n",
        "    df_feature_importance = pd.DataFrame({\n",
        "        'Feature': X_train.columns,\n",
        "        'Importance': classification_pipeline.feature_importances_\n",
        "    }).sort_values(by='Importance', ascending=False)\n",
        "    \n",
        "    # List of best features based on importance\n",
        "    best_features = df_feature_importance[\"Feature\"].to_list()\n",
        "    \n",
        "    print(f\"* These are the {len(best_features)} most important features in descending order.\\n\"\n",
        "          f\"* The model was trained using these features: {best_features}\")\n",
        "    \n",
        "    # Plotting the feature importances\n",
        "    df_feature_importance.plot(kind=\"bar\", x=\"Feature\", y=\"Importance\")\n",
        "    plt.title(\"Feature Importance in Employee Retention Analysis\")\n",
        "    plt.xlabel(\"Features\")\n",
        "    plt.ylabel(\"Importance\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"The selected model does not have a feature_importances_ attribute.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def confusion_matrix_and_report(X, y, pipeline, label_map):\n",
        "    prediction = pipeline.predict(X)\n",
        "\n",
        "    print('---  Confusion Matrix  ---')\n",
        "    print(pd.DataFrame(confusion_matrix(y_true=prediction, y_pred=y),\n",
        "          columns=[[\"Actual \" + sub for sub in label_map]],\n",
        "          index=[[\"Prediction \" + sub for sub in label_map]]\n",
        "          ))\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print('---  Classification Report  ---')\n",
        "    print(classification_report(y, prediction, target_names=label_map), \"\\n\")\n",
        "\n",
        "\n",
        "def clf_performance(X_train, y_train, X_test, y_test, pipeline, label_map):\n",
        "    print(\"#### Train Set #### \\n\")\n",
        "    confusion_matrix_and_report(X_train, y_train, pipeline, label_map)\n",
        "\n",
        "    print(\"#### Test Set ####\\n\")\n",
        "    confusion_matrix_and_report(X_test, y_test, pipeline, label_map)\n",
        "\n",
        "# Update the label_map to match the classes in the employee retention dataset\n",
        "clf_performance(X_train=X_train, y_train=y_train,\n",
        "                X_test=X_test, y_test=y_test,\n",
        "                pipeline=classification_pipeline,\n",
        "                label_map=[\"Stayed\", \"Left\"]\n",
        "                )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "To assess the performance of our classification model on employee retention, we performed evaluations on both the training and test sets. The key metrics include:\n",
        "\n",
        "- **Confusion Matrix**: Shows the actual vs. predicted values.\n",
        "- **Classification Report**: Provides precision, recall, and F1-score for the classes \"Stayed\" and \"Left.\"\n",
        "\n",
        "### Key Points:\n",
        "- **Train Set**: Used to evaluate the model’s performance on the data it was trained on.\n",
        "- **Test Set**: Used to assess how well the model generalizes to unseen data.\n",
        "- **Metrics**: Recall and precision were measured for \"Stayed\" and \"Left\" categories to ensure the model meets business requirements.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Refitting the ML Pipeline\n",
        "\n",
        "We refit the machine learning pipeline using the most important features identified from the feature importance analysis: EmployeeNumber, MonthlyIncome, Age, DailyRate, and YearsAtCompany. \n",
        "\n",
        "### Re-writing the ML Pipelines\n",
        "\n",
        "To ensure optimal performance:\n",
        "- **Data Cleaning and Feature Engineering Pipeline**: Focused on necessary preprocessing steps for the selected features.\n",
        "- **Modeling Pipeline**: Included steps for scaling the features and applying the best model.\n",
        "\n",
        "This refit aims to achieve a model that is both effective and efficient, focusing only on the most critical features for predicting employee retention.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "print(X_train.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from feature_engine.imputation import MeanMedianImputer\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "\n",
        "# Updated Data Cleaning and Feature Engineering Pipeline\n",
        "def DataCleaningandFeatEngPipeline():\n",
        "    pipeline = Pipeline([\n",
        "        (\"median_imputation\", MeanMedianImputer(imputation_method=\"median\", \n",
        "                                                variables=[\"MonthlyIncome\", \"Age\", \"DistanceFromHome\"])),\n",
        "        \n",
        "        (\"ordinal_encoding\", OrdinalEncoder(encoding_method=\"arbitrary\", \n",
        "                                            variables=[\"OverTime\", \"JobSatisfaction\", \"BusinessTravel\"])),\n",
        "    ])\n",
        "    return pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split Train and Test Sets Using Only Most Important Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop([\"Attrition\"], axis=1),  # Dropping the target variable\n",
        "    df[\"Attrition\"],  # Defining the target variable\n",
        "    test_size=0.2,  # Allocating 20% of data to the test set\n",
        "    random_state=0  # Ensuring reproducibility\n",
        ")\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filter the data to include only the most important features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = X_train.filter(best_features)  # Filtering train set\n",
        "X_test = X_test.filter(best_features)  # Filtering test set\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "X_train.head(3)  # Display the first few rows of the training data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Handle Target Imbalance\n",
        "\n",
        "To address the imbalance in the target variable (Attrition), we'll first clean and engineer the data, then apply SMOTE (Synthetic Minority Over-sampling Technique) to oversample the minority class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Apply SMOTE for oversampling the minority class\n",
        "oversample = SMOTE(sampling_strategy='minority', random_state=0)\n",
        "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
        "\n",
        "# Check the distribution after oversampling\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cross-Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We start by defining the model (AdaBoostClassifier) and the hyperparameters that will be used in the cross-validation process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_search = {\n",
        "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=0),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We store the Hyperparameter values in a list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Best hyperparameters for AdaBoostClassifier\n",
        "params_search = {\n",
        "    \"AdaBoostClassifier\": {\n",
        "        \"model__algorithm\": [\"SAMME.R\"],\n",
        "        \"model__learning_rate\": [1.0],\n",
        "        \"model__n_estimators\": [300],\n",
        "    },\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the HyperparameterOptimizationSearch function to run cross-validation on the defined model and parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "params_search = {\n",
        "    'RandomForestClassifier': {\n",
        "        'model__max_depth': [None],\n",
        "        'model__max_features': [None],\n",
        "        'model__max_leaf_nodes': [None],\n",
        "        'model__min_samples_leaf': [50],\n",
        "        'model__min_samples_split': [2],\n",
        "        'model__n_estimators': [50]\n",
        "    },\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import make_scorer, recall_score\n",
        "\n",
        "# Execute cross-validation with the correct pos_label\n",
        "quick_search.fit(X_train, y_train,\n",
        "                 scoring=make_scorer(recall_score, pos_label='Yes'),  # Use 'Yes' as pos_label\n",
        "                 n_jobs=-1, cv=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search_summary, grid_search_pipelines = quick_search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining the best classification pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_params = grid_search_pipelines[best_model].best_params_\n",
        "\n",
        "best_pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"model\", AdaBoostClassifier(**{\n",
        "        'algorithm': best_params['model__algorithm'],\n",
        "        'learning_rate': best_params['model__learning_rate'],\n",
        "        'n_estimators': best_params['model__n_estimators'],\n",
        "        'random_state': 0  # Ensure reproducibility\n",
        "    }))\n",
        "])\n",
        "\n",
        "best_pipeline.fit(X_train, y_train)\n",
        "\n",
        "classification_pipeline = best_pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation of Pipeline on Train and Test Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ML Business Case Metrics:\n",
        "\n",
        "- Recall on \"Yes\" (Employee Attrition): 75%\n",
        "- Precision on \"No\" (No Employee Attrition): 70%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the performance of the classification pipeline\n",
        "clf_performance(X_train=X_train, y_train=y_train,\n",
        "                X_test=X_test, y_test=y_test,\n",
        "                pipeline=classification_pipeline,\n",
        "                label_map=[\"No Attrition\", \"Yes Attrition\"]\n",
        "                )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the selected features, the recall for \"Yes Attrition\" was 97% on the train set and 67% on the test set. The precision for \"No Attrition\" was 97% on the train set and 91% on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Push Files to Repo\n",
        "\n",
        "The following files will be generated and saved:\n",
        "\n",
        "- Train set\n",
        "- Test set\n",
        "- Data cleaning and feature engineering pipeline\n",
        "- Modeling pipeline\n",
        "-Feature Importance plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "version = \"v2\"\n",
        "file_path = f\"outputs/ml_pipeline/classification_model/{version}\"\n",
        "\n",
        "try:\n",
        "    os.makedirs(name=file_path)\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Train Set\n",
        "\n",
        "Saving the train set with variables already encoded (and after oversampling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "X_train.head(3)\n",
        "\n",
        "X_train.to_csv(f\"{file_path}/X_train.csv\", index=False)\n",
        "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Test Set\n",
        "\n",
        "Save the test set with variables already encoded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(X_test.shape)\n",
        "X_test.head(3)\n",
        "\n",
        "X_test.to_csv(f\"{file_path}/X_test.csv\", index=False)\n",
        "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save ML Pipelines\n",
        "\n",
        "Two pipelines will be saved: one for data cleaning and feature engineering, and another for modeling.\n",
        "\n",
        "- When predicting live data, both pipelines will be required.\n",
        "\n",
        "\n",
        "- When predicting on the train and test sets, only the modeling pipeline is required as the data has already been processed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the data cleaning and feature engineering pipeline\n",
        "joblib.dump(value=data_cleaning_feat_eng_pipeline,\n",
        "            filename=f\"{file_path}/data_cleaning_and_feat_engineering_pipeline.pkl\")\n",
        "\n",
        "# Save the classification pipeline\n",
        "joblib.dump(value=classification_pipeline,\n",
        "            filename=f\"{file_path}/classification_pipeline.pkl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Feature Importance Plot\n",
        "\n",
        "Save the plot of feature importances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_feature_importance.plot(kind=\"bar\", x=\"Feature\", y=\"Importance\")\n",
        "plt.savefig(f\"{file_path}/features_importance.png\", bbox_inches=\"tight\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Modeling and Evaluation - Predict Customer Churn.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
